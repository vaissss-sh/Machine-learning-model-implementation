{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f74de97-b30f-43fd-ad32-a482f7c2e660",
   "metadata": {},
   "source": [
    "# Building Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655184ad-976d-4666-a429-22510a2bc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42dd8c-fa99-4f0d-9b1c-a54a688af17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression():\n",
    "\n",
    "    def __init__(self,learning_rate,no_of_iteration):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.no_of_iteration=no_of_iteration\n",
    "    \n",
    "    #fit function to tarin the model with dataset\n",
    "    def fit(self ,X ,Y):\n",
    "        #no. of data points in the dataset (no. of rows) --> m\n",
    "        # no. of input features (no. of columns)--> n\n",
    "        self.m,self.n=X.shape\n",
    "\n",
    "\n",
    "        #initializing weight and bias\n",
    "        self.w=np.zeros(self.n)\n",
    "        self.b=0\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        \n",
    "        \n",
    "        #implementing gradient descent\n",
    "        for i in range(self.no_of_iteration):\n",
    "            self.update_weights()\n",
    "\n",
    "\n",
    "    def update_weights(self):\n",
    "        #y_hat(sigmoid function)\n",
    "        Y_hat=1/(1+np.exp(-(self.X.dot(self.w)+self.b))) #z=wX+b\n",
    "        \n",
    "        #derivatives\n",
    "        dw=(1/self.m)*np.dot(self.X.T ,(Y_hat-self.Y))\n",
    "        db=(1/self.m)*np.sum(Y_hat-self.Y)\n",
    "\n",
    "        #updating weights and bias\n",
    "        self.w=self.w-self.learning_rate*dw\n",
    "        self.b=self.b-self.learning_rate*db\n",
    "        \n",
    "    #sigmoid equation and decision boundary\n",
    "    def predict(self):\n",
    "        Y_pred=1/(1+np.exp(-(self.X.dot(self.w)+self.b)))\n",
    "        Y_pred=np.where(Y_pred>0.5,1,0)\n",
    "        return Y_pred\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e88c32-5a2f-4bba-b213-f8d8c4087feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Logistic_Regression(learning_rate=0.01, no_of_iteration=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1393591-8d83-45b2-87a5-ccb2b79525e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
